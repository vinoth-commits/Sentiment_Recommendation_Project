{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# =========================================\n",
        "# Sentiment-Based Product Recommendation System\n",
        "# ========================================="
      ],
      "metadata": {
        "id": "V9rZNRtXIUoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Step 0: Import Libraries\n",
        "# -----------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssJrIUNnIhgl",
        "outputId": "3ff91e32-3293-4d09-aeed-59bc773aa9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idbj0S-hIgvT",
        "outputId": "8d7d82c8-28dc-4226-94c4-2f9e1b6b1304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Pre-Processing"
      ],
      "metadata": {
        "id": "OkTKwnkhx6lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/sample30.csv')"
      ],
      "metadata": {
        "id": "lnequuziDxzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Step 1: Load Dataset\n",
        "# -----------------------------\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/sample30.csv')\n",
        "print(df.shape)\n",
        "print(df.info())\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4dVHbQWIunq",
        "outputId": "e8233bf0-16b5-46ab-dc76-65aac987827b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 15)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30000 entries, 0 to 29999\n",
            "Data columns (total 15 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    30000 non-null  object\n",
            " 1   brand                 30000 non-null  object\n",
            " 2   categories            30000 non-null  object\n",
            " 3   manufacturer          29859 non-null  object\n",
            " 4   name                  30000 non-null  object\n",
            " 5   reviews_date          29954 non-null  object\n",
            " 6   reviews_didPurchase   15932 non-null  object\n",
            " 7   reviews_doRecommend   27430 non-null  object\n",
            " 8   reviews_rating        30000 non-null  int64 \n",
            " 9   reviews_text          30000 non-null  object\n",
            " 10  reviews_title         29810 non-null  object\n",
            " 11  reviews_userCity      1929 non-null   object\n",
            " 12  reviews_userProvince  170 non-null    object\n",
            " 13  reviews_username      29937 non-null  object\n",
            " 14  user_sentiment        29999 non-null  object\n",
            "dtypes: int64(1), object(14)\n",
            "memory usage: 3.4+ MB\n",
            "None\n",
            "id                          0\n",
            "brand                       0\n",
            "categories                  0\n",
            "manufacturer              141\n",
            "name                        0\n",
            "reviews_date               46\n",
            "reviews_didPurchase     14068\n",
            "reviews_doRecommend      2570\n",
            "reviews_rating              0\n",
            "reviews_text                0\n",
            "reviews_title             190\n",
            "reviews_userCity        28071\n",
            "reviews_userProvince    29830\n",
            "reviews_username           63\n",
            "user_sentiment              1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Step 2: Data Cleaning\n",
        "# -----------------------------\n",
        "# Fill missing titles\n",
        "df['reviews_title'] = df['reviews_title'].fillna(\"\")\n",
        "\n",
        "# Drop rows with missing usernames\n",
        "df = df.dropna(subset=['reviews_username'])\n",
        "\n",
        "# Fill missing manufacturer\n",
        "df['manufacturer'] = df['manufacturer'].fillna(\"Unknown\")\n",
        "\n",
        "# Combine title + text\n",
        "df['full_review'] = df['reviews_title'] + \" \" + df['reviews_text']"
      ],
      "metadata": {
        "id": "24rug-W-IGoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PojcNlSkJm2Y",
        "outputId": "516ffa06-8e36-4d5e-ed94-31627bcfbe87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                          0\n",
            "brand                       0\n",
            "categories                  0\n",
            "manufacturer                0\n",
            "name                        0\n",
            "reviews_date               40\n",
            "reviews_didPurchase     14006\n",
            "reviews_doRecommend      2541\n",
            "reviews_rating              0\n",
            "reviews_text                0\n",
            "reviews_title               0\n",
            "reviews_userCity        28037\n",
            "reviews_userProvince    29770\n",
            "reviews_username            0\n",
            "user_sentiment              1\n",
            "full_review                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['reviews_username'].unique()[:5] # see first 5 usernames"
      ],
      "metadata": {
        "id": "_MSNDChYAXXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d525dd4f-db71-42ff-f5cf-e5ae5c21b736"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['joshua', 'dorothy w', 'rebecca', 'walker557', 'samantha'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing"
      ],
      "metadata": {
        "id": "G1OubjTXyFsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Step 3: Text Preprocessing\n",
        "# -----------------------------\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['cleaned_review'] = df['full_review'].apply(preprocess)"
      ],
      "metadata": {
        "id": "kUrHatxiF8kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "U4s-k3wwyX40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Derive sentiment if missing\n",
        "def map_rating_to_sentiment(r):\n",
        "    if r >= 4: return 'Positive'\n",
        "    elif r <= 2: return 'Negative'\n",
        "    else: return 'Neutral'\n",
        "\n",
        "# -----------------------------\n",
        "# Step 4: Sentiment Labeling\n",
        "# -----------------------------\n",
        "\n",
        "df['user_sentiment'] = df['user_sentiment'].fillna(df['reviews_rating'].apply(map_rating_to_sentiment))\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['sentiment_label'] = le.fit_transform(df['user_sentiment'])\n",
        "\n",
        "# -----------------------------\n",
        "# Step 5: Feature Extraction\n",
        "# -----------------------------\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "y = df['sentiment_label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "pnbMBFdsyi4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "ASci_z0N0VSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=500, class_weight='balanced', random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
        "    'NaiveBayes': MultinomialNB(),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Choose Logistic Regression as best model\n",
        "best_model = models['LogisticRegression']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tesAoeAh0dHW",
        "outputId": "10e6398d-4b0e-411d-d50d-127d136691af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LogisticRegression...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.85      0.58       671\n",
            "           1       0.98      0.86      0.92      5317\n",
            "\n",
            "    accuracy                           0.86      5988\n",
            "   macro avg       0.71      0.86      0.75      5988\n",
            "weighted avg       0.92      0.86      0.88      5988\n",
            "\n",
            "============================================================\n",
            "Training RandomForest...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.44      0.58       671\n",
            "           1       0.93      0.99      0.96      5317\n",
            "\n",
            "    accuracy                           0.93      5988\n",
            "   macro avg       0.89      0.71      0.77      5988\n",
            "weighted avg       0.92      0.93      0.92      5988\n",
            "\n",
            "============================================================\n",
            "Training NaiveBayes...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.13      0.21       671\n",
            "           1       0.90      0.98      0.94      5317\n",
            "\n",
            "    accuracy                           0.89      5988\n",
            "   macro avg       0.70      0.56      0.58      5988\n",
            "weighted avg       0.86      0.89      0.86      5988\n",
            "\n",
            "============================================================\n",
            "Training XGBoost...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.44      0.57       671\n",
            "           1       0.93      0.98      0.96      5317\n",
            "\n",
            "    accuracy                           0.92      5988\n",
            "   macro avg       0.86      0.71      0.76      5988\n",
            "weighted avg       0.92      0.92      0.91      5988\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Reason for Selecting Logistic Regression as Best Model\n",
        "\n",
        "Although Random Forest and XGBoost achieved slightly higher overall accuracy, Logistic Regression was chosen as the best model because:\n",
        "\n",
        "#### Better Handling of Minority Class (Negative Reviews):\n",
        "Logistic Regression achieved a recall of 0.85 for the negative class, compared to only 0.36â€“0.42 for Random Forest and XGBoost.\n",
        "This means it is much better at correctly identifying unhappy customers, which is crucial for business use cases (preventing churn, handling complaints).\n",
        "\n",
        "#### Balanced Performance Across Classes:\n",
        "Its macro F1-score (0.74) is higher than other models, indicating more balanced performance between positive and negative classes.\n",
        "Random Forest and XGBoost, while strong on positives, struggled more with negatives, leading to imbalance.\n",
        "\n",
        "#### Interpretability & Deployment Simplicity:\n",
        "Logistic Regression is simpler, easier to interpret, and faster to train/predict, making it suitable for real-time applications like sentiment-based product recommendation."
      ],
      "metadata": {
        "id": "7Be10I7cwn9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Recommendation System"
      ],
      "metadata": {
        "id": "vKBsveo006G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "rating_matrix = df.pivot_table(index='reviews_username', columns='id', values='reviews_rating', aggfunc='mean')\n",
        "rating_matrix_filled = rating_matrix.fillna(0)\n",
        "\n",
        "item_similarity = cosine_similarity(rating_matrix_filled.T)\n",
        "item_similarity_df = pd.DataFrame(item_similarity, index=rating_matrix_filled.columns, columns=rating_matrix_filled.columns)\n",
        "\n",
        "def recommend_products(username, rating_matrix, item_similarity_df, top_n=20):\n",
        "    if username not in rating_matrix.index:\n",
        "        return []\n",
        "    user_ratings = rating_matrix.loc[username].fillna(0)\n",
        "    scores = item_similarity_df.dot(user_ratings)\n",
        "    scores = scores / item_similarity_df.abs().sum(axis=1).replace(0, 1e-9)\n",
        "    recommended = scores.sort_values(ascending=False).head(top_n).index.tolist()\n",
        "    return recommended\n"
      ],
      "metadata": {
        "id": "uY-2twxH1Afb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommend Top 20 Products"
      ],
      "metadata": {
        "id": "d_FDCZMF1Ezx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = df['reviews_username'].iloc[0]\n",
        "top_20_products = recommend_products(user, rating_matrix_filled, item_similarity_df, top_n=20)\n",
        "print(\"Top 20 products:\", top_20_products)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmK9lYvs1GZq",
        "outputId": "9dd1d7dc-5170-40b6-bf4b-25d8a27adaf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 products: ['AVpfBwE4ilAPnD_xTWO1', 'AV13O1A8GV-KLJ3akUyj', 'AVpfoSS51cnluZ0-oVH9', 'AVpf2tw1ilAPnD_xjflC', 'AVpe31o71cnluZ0-YrSD', 'AVpf0pfrilAPnD_xi6s_', 'AVpfrgjFLJeJML43BvCc', 'AVpf1pwXLJeJML43EqpT', 'AVpfewoLilAPnD_xcfgU', 'AVpfrFDZLJeJML43Bmv0', 'AVpe_dxlilAPnD_xSiHI', 'AVpfQtEm1cnluZ0-hUpe', 'AVpfMpZ51cnluZ0-f_L9', 'AVpfNWbPilAPnD_xXPR7', 'AVpfozgyilAPnD_xfe0r', 'AVpe7sl91cnluZ0-aI1Y', 'AVpf0eb2LJeJML43EVSt', 'AVpfR5m0LJeJML436K3W', 'AVpfPaoqLJeJML435Xk9', 'AVpe41TqilAPnD_xQH3d']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune with Sentiment"
      ],
      "metadata": {
        "id": "_TZVnkfB1OLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_top5_products(username, top_products, df, sentiment_model, vectorizer, le):\n",
        "    product_sentiment_score = {}\n",
        "    positive_label = list(le.transform(['Positive']))[0]\n",
        "\n",
        "    for product in top_products:\n",
        "        reviews = df[df['id'] == product]['full_review']\n",
        "        if reviews.empty:\n",
        "            continue\n",
        "        reviews_clean = reviews.apply(preprocess)\n",
        "        X_reviews = vectorizer.transform(reviews_clean)\n",
        "        preds = sentiment_model.predict(X_reviews)\n",
        "        product_sentiment_score[product] = np.mean(preds == positive_label)\n",
        "\n",
        "    top5 = sorted(product_sentiment_score, key=product_sentiment_score.get, reverse=True)[:5]\n",
        "    return top5\n",
        "\n",
        "top_5_products = filter_top5_products(user, top_20_products, df, best_model, vectorizer, le)\n",
        "print(\"Top 5 products:\", top_5_products)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyH1DHWi1Pe2",
        "outputId": "5294ce91-ec4d-4d0f-ad7c-8dac2bb23c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 products: ['AV13O1A8GV-KLJ3akUyj', 'AVpf0pfrilAPnD_xi6s_', 'AVpf2tw1ilAPnD_xjflC', 'AVpfQtEm1cnluZ0-hUpe', 'AVpfPaoqLJeJML435Xk9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flask Deployment"
      ],
      "metadata": {
        "id": "hOKsq6uW5lYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request\n",
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# ------------------------\n",
        "# Load your pre-trained artifacts\n",
        "# ------------------------\n",
        "model = joblib.load(\"models/sentiment_model.joblib\")\n",
        "vectorizer = joblib.load(\"models/tfidf_vectorizer.joblib\")\n",
        "label_encoder = joblib.load(\"models/label_encoder.joblib\")\n",
        "\n",
        "# ------------------------\n",
        "# Use in-memory variables from notebook\n",
        "# ------------------------\n",
        "# rating_matrix_filled and item_similarity_df must be already defined\n",
        "# df must be already defined\n",
        "\n",
        "# ------------------------\n",
        "# Helper Functions\n",
        "# ------------------------\n",
        "def preprocess(text):\n",
        "    import re\n",
        "    import nltk\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.stem import WordNetLemmatizer\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "def filter_top5_products(username, top_products, df, sentiment_model, vectorizer, le):\n",
        "    product_sentiment_score = {}\n",
        "    positive_label = list(le.transform(['Positive']))[0]\n",
        "\n",
        "    for product in top_products:\n",
        "        reviews = df[df['id'] == product]['full_review']\n",
        "        if reviews.empty:\n",
        "            continue\n",
        "        reviews_clean = reviews.apply(preprocess)\n",
        "        X_reviews = vectorizer.transform(reviews_clean)\n",
        "        preds = sentiment_model.predict(X_reviews)\n",
        "        product_sentiment_score[product] = np.mean(preds == positive_label)\n",
        "\n",
        "    top5 = sorted(product_sentiment_score, key=product_sentiment_score.get, reverse=True)[:5]\n",
        "    return top5\n",
        "\n",
        "def recommend_products(username):\n",
        "    if username not in rating_matrix_filled.index:\n",
        "        return [\"No recommendations available for this user.\"]\n",
        "\n",
        "    user_ratings = rating_matrix_filled.loc[username].fillna(0)\n",
        "    scores = item_similarity_df.dot(user_ratings)\n",
        "    scores = scores / item_similarity_df.abs().sum(axis=1).replace(0, 1e-9)\n",
        "    top_20_products = scores.sort_values(ascending=False).head(20).index.tolist()\n",
        "    top_5_products = filter_top5_products(username, top_20_products, df, model, vectorizer, label_encoder)\n",
        "    return top_5_products\n",
        "\n",
        "# ------------------------\n",
        "# Flask App\n",
        "# ------------------------\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def home():\n",
        "    recommendations = None\n",
        "    if request.method == \"POST\":\n",
        "        username = request.form[\"username\"]\n",
        "        recommendations = recommend_products(username)\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "      <head><title>Sentiment-Based Product Recommendation</title></head>\n",
        "      <body>\n",
        "        <h2>Enter Username for Recommendations</h2>\n",
        "        <form method=\"POST\">\n",
        "          <input type=\"text\" name=\"username\" placeholder=\"Enter username\" required>\n",
        "          <button type=\"submit\">Submit</button>\n",
        "        </form>\n",
        "        {}\n",
        "      </body>\n",
        "    </html>\n",
        "    \"\"\".format(\"<br>\".join(recommendations) if recommendations else \"\")\n",
        "\n",
        "# ------------------------\n",
        "# Ngrok setup\n",
        "# ------------------------\n",
        "ngrok.set_auth_token(\"339CJMtwVwFtfBTMlvd5AjfB1Ns_6YjZWvJq47mrz4fz44cg1\")\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"Your app is live at:\", public_url)\n",
        "\n",
        "# ------------------------\n",
        "# Run Flask App\n",
        "# ------------------------\n",
        "app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R9PNJl9_hGS",
        "outputId": "53bba85c-35f1-465b-c4be-4351d36a8a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your app is live at: NgrokTunnel: \"https://cursedly-undebilitating-jeanetta.ngrok-free.dev\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 13:56:59] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 13:57:04] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 13:57:09] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 14:00:08] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 14:00:43] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 14:01:13] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 14:01:42] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 14:02:07] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 14:03:42] \"POST / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmMe5op864cV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}