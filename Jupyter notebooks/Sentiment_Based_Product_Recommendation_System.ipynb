{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErD5zEI4vu_B"
      },
      "source": [
        "# Sentiment-Based Product Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-F8s4tRv5RK"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQYUPGamvrcs",
        "outputId": "aacb2a84-c3f5-485b-d9c0-98f1ba779c7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================\n",
        "# Step 0: Import Libraries\n",
        "# =========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import joblib, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idbj0S-hIgvT",
        "outputId": "a352c134-eed8-40d0-bb10-b92c2a018080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkTKwnkhx6lh"
      },
      "source": [
        "# Task-1: Data Cleaning and Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnequuziDxzw",
        "outputId": "a4baccbd-1028-40fd-d403-be1464115802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(30000, 15)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30000 entries, 0 to 29999\n",
            "Data columns (total 15 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    30000 non-null  object\n",
            " 1   brand                 30000 non-null  object\n",
            " 2   categories            30000 non-null  object\n",
            " 3   manufacturer          29859 non-null  object\n",
            " 4   name                  30000 non-null  object\n",
            " 5   reviews_date          29954 non-null  object\n",
            " 6   reviews_didPurchase   15932 non-null  object\n",
            " 7   reviews_doRecommend   27430 non-null  object\n",
            " 8   reviews_rating        30000 non-null  int64 \n",
            " 9   reviews_text          30000 non-null  object\n",
            " 10  reviews_title         29810 non-null  object\n",
            " 11  reviews_userCity      1929 non-null   object\n",
            " 12  reviews_userProvince  170 non-null    object\n",
            " 13  reviews_username      29937 non-null  object\n",
            " 14  user_sentiment        29999 non-null  object\n",
            "dtypes: int64(1), object(14)\n",
            "memory usage: 3.4+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# Load Dataset\n",
        "# =========================================\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/sample30.csv')\n",
        "print(df.shape)\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1gNa22hwepg",
        "outputId": "13f799d8-0073-4d4f-a3ab-f799ff19d3e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 29937 entries, 0 to 29999\n",
            "Data columns (total 12 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   id                29937 non-null  object\n",
            " 1   brand             29937 non-null  object\n",
            " 2   categories        29937 non-null  object\n",
            " 3   manufacturer      29937 non-null  object\n",
            " 4   name              29937 non-null  object\n",
            " 5   reviews_rating    29937 non-null  int64 \n",
            " 6   reviews_text      29937 non-null  object\n",
            " 7   reviews_title     29937 non-null  object\n",
            " 8   reviews_username  29937 non-null  object\n",
            " 9   user_sentiment    29937 non-null  object\n",
            " 10  full_review       29937 non-null  object\n",
            " 11  sentiment_label   29937 non-null  int64 \n",
            "dtypes: int64(2), object(10)\n",
            "memory usage: 3.0+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# Step 1: Data Cleaning & Preprocessing\n",
        "# =========================================\n",
        "irrelevant_columns = [\n",
        "    'reviews_userCity',\n",
        "    'reviews_userProvince',\n",
        "    'reviews_date',\n",
        "    'reviews_didPurchase',\n",
        "    'reviews_doRecommend'\n",
        "]\n",
        "df.drop(columns=irrelevant_columns, inplace=True)\n",
        "\n",
        "df['reviews_title'] = df['reviews_title'].fillna(\"\")\n",
        "df['manufacturer'] = df['manufacturer'].fillna(\"Unknown\")\n",
        "df = df.dropna(subset=['reviews_username'])\n",
        "\n",
        "df['full_review'] = df['reviews_title'] + \" \" + df['reviews_text']\n",
        "df['reviews_rating'] = df['reviews_rating'].astype(int)\n",
        "df['id'] = df['id'].astype(str)\n",
        "df['reviews_username'] = df['reviews_username'].astype(str)\n",
        "\n",
        "def map_rating_to_sentiment(r):\n",
        "    if r >= 4: return 'Positive'\n",
        "    elif r <= 2: return 'Negative'\n",
        "    else: return 'Neutral'\n",
        "\n",
        "df['user_sentiment'] = df['user_sentiment'].fillna(df['reviews_rating'].apply(map_rating_to_sentiment))\n",
        "le = LabelEncoder()\n",
        "df['sentiment_label'] = le.fit_transform(df['user_sentiment'])\n",
        "\n",
        "# final dataset\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xyR6cgn1qxK"
      },
      "source": [
        "# Task-2: Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6sypFD0cwszj"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Step 2: Text Preprocessing\n",
        "# =========================================\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^a-z\\s]', '', text.lower())\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['cleaned_review'] = df['full_review'].apply(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJUMFvsizpOE"
      },
      "source": [
        "# Task-3: Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hl9qs84uwwAY"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Step 3: Feature Extraction\n",
        "# =========================================\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "y = df['sentiment_label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK7NhNdLzwSW"
      },
      "source": [
        "# Task-4: Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWctu94sw2Hk",
        "outputId": "6cd15c95-e0fd-4536-acbc-51130ff8bb0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LogisticRegression...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.85      0.58       671\n",
            "           1       0.98      0.86      0.92      5317\n",
            "\n",
            "    accuracy                           0.86      5988\n",
            "   macro avg       0.71      0.86      0.75      5988\n",
            "weighted avg       0.92      0.86      0.88      5988\n",
            "\n",
            "============================================================\n",
            "Training RandomForest...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.44      0.58       671\n",
            "           1       0.93      0.99      0.96      5317\n",
            "\n",
            "    accuracy                           0.93      5988\n",
            "   macro avg       0.89      0.71      0.77      5988\n",
            "weighted avg       0.92      0.93      0.92      5988\n",
            "\n",
            "============================================================\n",
            "Training NaiveBayes...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.13      0.21       671\n",
            "           1       0.90      0.98      0.94      5317\n",
            "\n",
            "    accuracy                           0.89      5988\n",
            "   macro avg       0.70      0.56      0.58      5988\n",
            "weighted avg       0.86      0.89      0.86      5988\n",
            "\n",
            "============================================================\n",
            "Training XGBoost...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.44      0.57       671\n",
            "           1       0.93      0.98      0.96      5317\n",
            "\n",
            "    accuracy                           0.92      5988\n",
            "   macro avg       0.86      0.71      0.76      5988\n",
            "weighted avg       0.92      0.92      0.91      5988\n",
            "\n",
            "============================================================\n",
            "Selected best model: RandomForest with accuracy: 0.93\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# Step 4: Model Building\n",
        "# =========================================\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=500, class_weight='balanced', random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
        "    'NaiveBayes': MultinomialNB(),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "model_performance = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    model_performance[name] = report['accuracy']  # Store accuracy for comparison\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Select the best model based on overall accuracy\n",
        "best_model_name = max(model_performance, key=model_performance.get)\n",
        "best_model = models[best_model_name]\n",
        "print(f\"Selected best model: {best_model_name} with accuracy: {model_performance[best_model_name]:.2f}\")\n",
        "\n",
        "# RandomForest is selected because:\n",
        "# 1. It achieves the highest overall accuracy (0.93) among all models.\n",
        "# 2. Weighted F1-score is the best, giving good balance between majority and minority classes.\n",
        "# 3. Handles class imbalance better in practice, with robust performance on unseen data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeFwrGtfz0le"
      },
      "source": [
        "# Task-5: Building the Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FNY2pbD6w7E9"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Step 5: Build Recommendation Systems\n",
        "# =========================================\n",
        "rating_matrix = df.pivot_table(index='reviews_username', columns='id', values='reviews_rating', aggfunc='mean')\n",
        "rating_matrix_filled = rating_matrix.fillna(0)\n",
        "\n",
        "# --- Item-based ---\n",
        "item_similarity = cosine_similarity(rating_matrix_filled.T)\n",
        "item_similarity_df = pd.DataFrame(item_similarity, index=rating_matrix_filled.columns, columns=rating_matrix_filled.columns)\n",
        "\n",
        "def recommend_products_item(username, rating_matrix, item_similarity_df, top_n=20):\n",
        "    if username not in rating_matrix.index:\n",
        "        return []\n",
        "    user_ratings = rating_matrix.loc[username].fillna(0)\n",
        "    scores = item_similarity_df.dot(user_ratings)\n",
        "    scores = scores / item_similarity_df.abs().sum(axis=1).replace(0, 1e-9)\n",
        "    return scores.sort_values(ascending=False).head(top_n).index.tolist()\n",
        "\n",
        "# --- User-based ---\n",
        "user_similarity = cosine_similarity(rating_matrix_filled)\n",
        "user_similarity_df = pd.DataFrame(user_similarity, index=rating_matrix_filled.index, columns=rating_matrix_filled.index)\n",
        "\n",
        "def recommend_products_user(username, rating_matrix, user_similarity_df, top_n=20):\n",
        "    if username not in rating_matrix.index:\n",
        "        return []\n",
        "    sim_scores = user_similarity_df[username]\n",
        "    weighted_ratings = rating_matrix.T.dot(sim_scores) / sim_scores.sum()\n",
        "    return weighted_ratings.sort_values(ascending=False).head(top_n).index.tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F1NXWKC27wd"
      },
      "source": [
        "# Task-6: Recommendation of TOP 20 Products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkn7dVE320jY",
        "outputId": "f7c8e7f2-e5c8-442b-9c6f-0b2e5b2fa76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 20 products recommended for user 'joshua' using the  system:\n",
            "['AV13O1A8GV-KLJ3akUyj', 'AV14LG0R-jtxr-f38QfS', 'AV16khLE-jtxr-f38VFn', 'AV1YGDqsGV-KLJ3adc-O', 'AV1YIch7GV-KLJ3addeG', 'AV1YlENIglJLPUi8IHsX', 'AV1YmBrdGV-KLJ3adewb', 'AV1YmDL9vKc47QAVgr7_', 'AV1Ymf_rglJLPUi8II2v', 'AV1Yn94nvKc47QAVgtst', 'AV1YnUMYglJLPUi8IJpK', 'AV1Ynb3bglJLPUi8IJxJ', 'AV1YneDPglJLPUi8IJyQ', 'AV1Yo6FPglJLPUi8IK3u', 'AV1YpiJvvKc47QAVguxy', 'AV1YqAaMGV-KLJ3adiDj', 'AV1Ys0kTvKc47QAVgx1C', 'AV1YtGjdglJLPUi8IOfJ', 'AV1ZSp2uglJLPUi8IQFy', 'AV1ZT7GLglJLPUi8IQLI']\n",
            "Avg rating item-based: 0.25, user-based: 0.25\n",
            "Best recommendation system: Item-based\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# Step 6: Recommend Top 20 Products for a Specified User\n",
        "# =========================================\n",
        "\n",
        "# Pick any sample user from the dataset\n",
        "sample_username = df['reviews_username'].dropna().iloc[0]\n",
        "best_system = ''\n",
        "if best_system == 'Item-based':\n",
        "    top20_products = recommend_products_item(sample_username, rating_matrix, item_similarity_df, top_n=20)\n",
        "else:\n",
        "    top20_products = recommend_products_user(sample_username, rating_matrix, user_similarity_df, top_n=20)\n",
        "\n",
        "print(f\"\\nTop 20 products recommended for user '{sample_username}' using the {best_system} system:\")\n",
        "print(top20_products)\n",
        "\n",
        "# --- Evaluate which system is better ---\n",
        "def evaluate_system(usernames, top_n=20):\n",
        "    item_scores, user_scores = [], []\n",
        "    for u in usernames:\n",
        "        if u not in rating_matrix_filled.index:\n",
        "            continue\n",
        "        top_items = recommend_products_item(u, rating_matrix_filled, item_similarity_df, top_n)\n",
        "        top_users = recommend_products_user(u, rating_matrix_filled, user_similarity_df, top_n)\n",
        "        item_scores.append(rating_matrix_filled.loc[u, top_items].mean())\n",
        "        user_scores.append(rating_matrix_filled.loc[u, top_users].mean())\n",
        "    avg_item = np.mean(item_scores)\n",
        "    avg_user = np.mean(user_scores)\n",
        "    print(f\"Avg rating item-based: {avg_item:.2f}, user-based: {avg_user:.2f}\")\n",
        "    return 'Item-based' if avg_item >= avg_user else 'User-based'\n",
        "\n",
        "best_system = evaluate_system(rating_matrix_filled.index.tolist())\n",
        "print(f\"Best recommendation system: {best_system}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9EH16R9z6dL"
      },
      "source": [
        "# Task-7: Fine-tune Top 5 Products with Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "R0iiJ1u6xAl_"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Step 7: Fine-tune Top 5 Products with Sentiment\n",
        "# =========================================\n",
        "def filter_top5_products(username, top_products, df, sentiment_model, vectorizer, le):\n",
        "    product_sentiment_score = {}\n",
        "    positive_label = le.transform(['Positive'])[0]\n",
        "    for product in top_products:\n",
        "        reviews = df[df['id'] == product]['full_review']\n",
        "        if reviews.empty:\n",
        "            continue\n",
        "        reviews_clean = reviews.apply(preprocess)\n",
        "        X_reviews = vectorizer.transform(reviews_clean)\n",
        "        preds = sentiment_model.predict(X_reviews)\n",
        "        product_sentiment_score[product] = np.mean(preds == positive_label)\n",
        "    top5 = sorted(product_sentiment_score, key=product_sentiment_score.get, reverse=True)[:5]\n",
        "    return top5\n",
        "\n",
        "def recommend(username):\n",
        "    if username not in rating_matrix_filled.index:\n",
        "        return [\"No recommendations available for this user.\"]\n",
        "\n",
        "    if best_system == 'Item-based':\n",
        "        top_20 = recommend_products_item(username, rating_matrix_filled, item_similarity_df)\n",
        "    else:\n",
        "        top_20 = recommend_products_user(username, rating_matrix_filled, user_similarity_df)\n",
        "\n",
        "    top_5 = filter_top5_products(username, top_20, df, best_model, vectorizer, le)\n",
        "    return top_5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkhZZ204z_ci"
      },
      "source": [
        "# Task-8: Flask Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "SG36TKn3xJ2h"
      },
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Step 8: Flask Deployment\n",
        "# =========================================\n",
        "import flask\n",
        "from flask import Flask, request\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ------------------------\n",
        "# Flask App\n",
        "# ------------------------\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def home():\n",
        "    recommendations = None\n",
        "    username = None\n",
        "    if request.method == \"POST\":\n",
        "        username = request.form[\"username\"]\n",
        "        recommendations = recommend_products(username)\n",
        "\n",
        "    # Updated HTML\n",
        "    html_content = \"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "        <title>Welcome to Sentiment-Based Product Recommendation</title>\n",
        "        <style>\n",
        "            body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
        "            h2, h3 {{ color: #333; }}\n",
        "            input {{ padding: 8px; margin-right: 10px; width: 250px; }}\n",
        "            button {{ padding: 8px 16px; }}\n",
        "            ul {{ list-style-type: none; padding-left: 0; }}\n",
        "            li {{ margin: 5px 0; }}\n",
        "            .no-recommend {{ color: red; }}\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <h1>Welcome to Sentiment-Based Product Recommendation</h1>\n",
        "        <h2>Enter Username for Recommendations</h2>\n",
        "        <form method=\"POST\">\n",
        "            <input type=\"text\" name=\"username\" placeholder=\"Enter username\" required>\n",
        "            <button type=\"submit\">Submit</button>\n",
        "        </form>\n",
        "        {recommendations_html}\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    # Build recommendations HTML\n",
        "    if recommendations:\n",
        "        if recommendations[0] == \"No recommendations available for this user.\":\n",
        "            recommendations_html = f'<p class=\"no-recommend\">{recommendations[0]}</p>'\n",
        "        else:\n",
        "            recommendations_html = f\"<h3>Top 5 Product Recommendations for <b>{username}</b>:</h3><ul>\"\n",
        "            for product in recommendations:\n",
        "                recommendations_html += f\"<li>{product}</li>\"\n",
        "            recommendations_html += \"</ul>\"\n",
        "    else:\n",
        "        recommendations_html = \"\"\n",
        "\n",
        "    return html_content.format(recommendations_html=recommendations_html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU4DwlcIxLHW",
        "outputId": "a6eba298-20f3-4d12-d623-86650981d8f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your app is live at: NgrokTunnel: \"https://cursedly-undebilitating-jeanetta.ngrok-free.dev\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 18:14:37] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 18:14:41] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 18:14:44] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 18:14:48] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 18:14:53] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 18:15:00] \"POST / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [24/Sep/2025 18:15:05] \"POST / HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "# ------------------------\n",
        "# Ngrok setup\n",
        "# ------------------------\n",
        "ngrok.set_auth_token(\"XXXXXXXX\") # Put your keys here \n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"Your app is live at:\", public_url)\n",
        "\n",
        "# ------------------------\n",
        "# Run Flask App\n",
        "# ------------------------\n",
        "app.run(port=5000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
